---
marp: true
---

# 实体链接综述——基础篇

邱日宏

2023.8.6

---

# 实体链接简介

---

## Entity Linking的定义

实体链接是将**文本中提到的实体（mention）** 与其**知识库中相应的实体 （entity）** 链接起来的任务，是解决实体间存在的歧义性问题。

详细来说，给定一个富含一系列实体的知识库与已经标注好mention的语料，实体链接任务的目标是将每一个mention匹配到知识库中它所对应的实体上面，如果知识库中没有mention对应的实体，则认为该mention不可链接到当前知识库，标记为NIL.

---

## Knowledge Graph

- **Knowledge Graph (知识图谱)**：一种语义网络，旨在描述客观世界的概念实体及其之间的关系，有时也称为Knowledge Base (知识库)。
  - 图谱由三元组构成：<实体1，关系，实体2> 或者 <实体，属性，属性值>；
  - 例如：<姚明，plays-in，NBA>、<姚明，身高，2.29m>；
  - 常见的KB有：Wikidata、DBpedia、YAGO.

## Entity

- **Entity (实体)**：实体是知识图谱的基本单元，也是文本中承载信息的重要语言单位。

## Mention

- **Mention (提及)**：自然文本中表达实体的语言片段。

---

## Entity Linking的分类

大体来说，EL的工作可以分为两类：

- **End-to-End**：先从文本中提取到实体mention (即NER)，对应到候选实体，然后将提取到的entities消除歧义，映射到给定的KB中。
- **Linking-Only**：与第一种方法对比，跳过了第一步。该方法直接将text和mention作为输入，找到候选实体并消除歧义，映射到给定的KB中.

---

![Entity Linking Classification](https://cdn.nlark.com/yuque/0/2023/png/27430994/1691164375023-723f11dc-65ad-4c9c-a40c-341f0719b6e9.png#averageHue=%23f4f4f4&clientId=u7074fe25-1df9-4&from=paste&height=230&id=uc76375a2&originHeight=459&originWidth=1080&originalType=url&ratio=1.25&rotation=0&showTitle=false&status=done&style=none&taskId=u2d22aa96-3b56-45f5-80a2-f742fb70134&title=&width=540)

---

## Entity Linking的分类

其实归根到底，第一步文本中的实体识别操作是必要做的，实践者必须在中间或者起始阶段获取指代实体，两种方法所不同的是将NER步骤跟EL步骤合并在一起做还是分割开来做。

---

### Entity Linking的挑战

EL的工作非常有挑战性，主要有两个原因：

1. **Mention Variations**：同一实体有不同的mention。（<科比>：小飞侠、黑曼巴、科铁、蜗壳、老科。）
2. **Entity Ambiguity**：同一mention对应不同的实体。（“苹果”：中关村苹果不错；山西苹果不错。）

此外，对于中文实体链接而言，(1) 实体链接属于相对下游的任务，其性能受限于中文分词和实体识别的准确性；(2) 英文有TAC-KBP等公开数据集，标注完整且较为准确，中文相关领域缺乏权威数据集；(3) 相较于Wikipedia、YAGO、Freebase等知识库，中文百科知识库起步较晚且不成熟。

---

### Entity Linking的应用

1. Question Answering：实体链接是KB-QA（Knowledge Based Question Answer）的刚需，linking到实体之后才能查询图数据库。
2. Content analysis：舆情分析、内容推荐、阅读增强。
3. Information retrieval：基于语义实体的搜索引擎，例如在Google搜索一些实体，右侧会出现wikipedia页面。
4. Knowledge base population：扩充知识库，更新实体和关系。

---

# 实体链接技术

---

### 命名实体识别 Named Entity Recognition（NER）

---

### 命名实体识别 Named Entity Recognition（NER）

实体链接的第一步得先识别出文本中的实体，被称为NER。命名实体识别(Named Entity Recognition)是识别出文本中的人名、地名等专有名称和有意义的时间、日期等相关实体并加以归类。而且NER的准确度将直接影响到下有任务实体连接的效果，因此至关重要。

---

### 候选实体生成 Candidate Entity Generation (CEG)

---

### 候选实体生成 Candidate Entity Generation (CEG)

候选实体集的生成是根据文本中已有的指称项，去知识库中召回与之相关尽可能多的实体，该过程要求较高的召回率。

---

### 候选实体生成 Candidate Entity Generation (CEG)

候选实体生成的常见方案有以下这些。

1. 构建同义词表：名字大致相同的情况。可以根据百科中（Wiki百科）的重定向页面，抽取同义词，或者从Wiki百科中首段加粗内容抽取同义词。
2. 构建缩写全称映射表：对于人名，名字扩展成为全称。对于大写缩写，可根据库中实体核对首字母。对于地名，可根据地名表扩展。
3. 构建别名词表：别名词表，内容大致为名称不太相同，但是意义一致的内容。如：鲁迅与周树人。可根据wiki中的锚文本信息中抽取别名。
4. 基于编辑距离召回实体：给定指称项，根据实体计算知识库中候选实体与实体的编辑距离，小于阈值则可以召回。其中，编辑距离是两字字符串A、B的字面相似度，指字符串A到字符串B经增加，删除或替换一个字符，所需的最少编辑操作次数。
5. 基于词向量相似性召回实体：根据文本训练词向量，将实体的词向量与文本中的词向量计算词向量之间的相似度，例如余弦相似度等。

---

### 候选实体生成 Candidate Entity Generation (CEG)

CEG这部分，最主流也最有效的方法就是Name Dictionary ( {mention: entity} )

- 构建方法：
  - Wikipedia（Redirect pages, Disambiguation pages, Hyperlinks）；
  - 基于搜索引擎：调google api，搜mention。若前m个有wiki entity，建立map；
  - Heuristic Methods；
  - 人工标注、用户日志。

---

### 候选实体生成 Candidate Entity Generation (CEG)

具体的，要配置哪些别名，要用什么构建方法，往往取决于EL的使用场景。比如做百科问答或是通用文本的阅读增强，就很依赖于**wikipedia和搜索引擎**；但如果是某个具体的行业领域，就需要通过一些**启发式的方法、用户日志、网页爬取，甚至人工标注的方法**来构建Name Dictionary。

---

### 实体消歧 Entity Disambiguation (ED)

---

### 实体消歧 Entity Disambiguation (ED)

实体消歧是指解决同名实体存在的一词多义歧义问题。实体消歧研究中常用的方法是基于实体链接的实体消歧，通常链接的目标知识库为Wikipedia。随着知识图谱的发展，基于知识图谱的实体消歧研究逐渐增多。

有监督学习方法和无监督学习方法两种策略用于实体消歧。

---

#### 实体消歧 Entity Disambiguation (ED)

##### 有监督学习方法

实体消歧时，有监督学习常常基于一些**特征**来进行消除歧义。不同场景的特征选取是非常重要的。总的来说，实体消歧的特征分为，context-dependent（上下文相关）和context-independent（上下文无关）的。

- Features
  - Context-Independent Features：
    - LinkCount：#(m->e)，知识库中某个提及m指向实体e的次数；
    - Entity Attributes：Popularity、Type；
  - Context-Dependent Features：
    - Textual Context：BOW, Concept Vector
    - Coherence Between Entities：WLM、PMI、Jaccard Distance

---

##### 有监督学习方法

###### 上下文无关特征

**上下文无关特征（context-independent feature）** 仅基于实体提及和候选实体本身对不同候选实体进行打分和排序。常用的上下文无关特征包括：

- 实体提及和候选实体的名称是否完全匹配；
- 实体提及（或候选实体）是否以候选实体（或实体提及）作为前缀或后缀；
- 实体提及（或候选实体）是否完全包含候选实体（或实体提及）；
- 实体提及所包含单词的首字母序列是否和候选实体所包含首字母序列相同；
- 实体提及和候选实体共同包含的单词数目；
- 候选实体流行度特征，表示实体提及m链接到候选实体的先验概率；
- 实体提及和候选实体之间的类型匹配特征。该特征对比实体提及的NER类型（例如 People, Location、Organization 等）与候选实体在知识图谱中的类型是否一致。

---

##### 有监督学习方法

###### 上下文无关特征

其中，**LinkCount作为一个先验知识，在消歧时，往往很有用**，比如当我们在问“姚明有多高？”时，大概率都是在问<篮球运动员姚明>，而不是其他不为人知的“姚明”。虽然context中完全没有包含篮球运动员这一信息，但大多数情况下，根据“姚明”到<篮球运动员姚明>的LinkCount最高，选其作为实体进行查询，都会是一个不错的答案。

---

##### 有监督学习方法

###### 上下文相关特征

**上下文相关特征（context-dependent feature）** 基于实体提及和候选实体所在上下文之间的相关度对不同候选实体进行打分和排序。常用的上下文相关特征包括：

- 词袋特征：通过将实体提及和候选实体分别表示为向量形式，计算二者之间的相似性。实体提及向量等于该实体提及所在上下文对应的词袋向量表示。候选实体向量根据实体的来源不同，生成的方式也不同：对于来自维基百科的候选实体，该向量等于该实体维基百科页面对应的词袋向量表示；对于来自知识图谱的候选实体，该向量等于与该实体直接相连的知识图谱实体和谓词对应的词袋向量表示。
- 概念向量特征：专门针对基于维基百科的实体链接任务。对于每个候选实体，基于该实体维基百科页面中的重定向、锚文本、关键词、InfoBox等信息生成一个概念向量，并计算其与实体提及上下文对应词袋向量之间的相似度。

---

##### 有监督学习方法

###### 上下文相关特征

其中，文本context可以用一些深度学习的方法去深度理解文本的语义，从而实现消歧；实体间的一致性更加有趣，由于文本包含的所有的mention都没有确定，所以**全局地进行entities的消歧实际上是一个NP-hard的问题**。因此，如何更加快速有效地利用一致性特征，是一个非常有趣的方向。

---

#### 实体消歧 Entity Disambiguation (ED)

##### 有监督学习方法

基于这些常用的特征，消歧的方法可以大致分为以下几种：

- Learning to Rank Methods：Point-wise、Pair-wise、List-wise。由于ED任务ground truth只有一个实体，一般都是用point-wise来做。输入是文本的context、mention、某个entity的一些attributes，输出mention指向该entity的置信度，以此rank，选出最可信的entity；
- Probabilistic Methods：Incorporate heterogeneous knowledge into a probabilistic model。结合不同信息，得到条件概率 P(e|m, c)，其中 c 是输入文本，e 为实体，m 是mention。比如用归一化的LinkCount信息，作为先验概率 P(e|m)；
- Graph-Based Approaches：maximize coherene between entities。利用图特征 (entity embedding、relation)，在消歧时，考虑全局消歧后实体的一致性。

---

#### 实体消歧 Entity Disambiguation (ED)

##### 无监督学习方法

为了减少实体链接系统对标注数据的需求，可以将无监督学习方法用于候选实体排序任务。常用的方法包括基于向量空间模型的方法和基于信息检索的方法。

- 基于向量空间模型的方法首先将实体提及m和m对应的某个候选实体分别转化为向量表示。然后，通过计算这两个向量表示之间的距离对不同候选实体进行排序。实体提及和候选实体的不同向量表示生成方法对应了不同的工作。
- 基于信息检索的方法将每个知识图谱实体对应的维基百科文档作为该实体的表示，并基于该类文档对全部知识图谱实体建立索引。给定输入文本中的一个实体提及m，该类方法首先从输入文本中找到包含m的全部句子集合，并通过去停用词等过滤操作生成一个查询语句。然后，使用该查询语句从知识图谱实体对应的索引中查找得到相关性最高的知识图谱实体，作为m的实体链接结果。

---

### 无链接指代预测 Unlinkable Mention Prediction

---

### 无链接指代预测 Unlinkable Mention Prediction

无链接指代预测（unlinkable mention prediction)负责预测输入文本中哪些实体提及是无法被链接到知识图谱中去的。这种情况通常是由知识图谱本身的不完备性导致的，即输入文本中提及的实体尚未被现有知识图谱覆盖（在知识图谱中找不到对应的实体）。

由于知识图谱的不完备性，并不是每个实体提及在知识图谱中都能够找到对应的实体。对于这类实体提及，实体链接系统通常将其链接到一个特殊的“空实体”（NIL），表示该实体提及无法被链接到任何已知实体。

---

#### 无链接指代预测 Unlinkable Mention Prediction

无链接指代预测是实体链接中的一个重要子任务，其目标是尽可能准确地预测哪些实体提及是无法被链接到知识图谱中去的，从而避免将其错误地链接到“空实体”。常用的方法包括基于规则的方法和基于机器学习的方法。

---

#### 无链接指代预测 Unlinkable Mention Prediction

无链接提及预测任务常用的策略有以下几种：

- **NIL**：如果一个实体提及对应的候选实体生成结果是空集，那么该实体提及的链接结果是NIL;
- **NIL Threshold**：设置一个**置信度的阈值**。如果一个实体提及对应排名最高的候选实体得分低于一个预先设定的阈值，那么该实体提及的链接结果是 NIL.这里用到的阈值通常根据系统在标注数据上的表现进行预设；
- **Binary Classification**：给定一个实体提及及其对应排名最高的候选实体，使用**二分类器**对其进行分类。如果分类结果是1,则返回候选实体作为实体链接结果。否则，该实体提及的链接结果是 NIL. 
- **Rank with NIL**：在rank的时候，在候选实体中加入NIL Entity。将NIL 作为一个特殊的实体直接加到每个实体提及对应的候选实体集合中进行打分和排序。


---

## 心得体会

---

实体链接的意义：

- 帮助理解文本中的实体指称，提升对实体的理解和认知。
- 改善知识库的查询效率和准确性，提高知识库的应用价值。
- 在问答、内容分析、信息检索等领域有广泛的应用。

---

实体链接的不足：

- 实体消歧的性能受限于中文分词和实体识别的准确性。
- 缺乏中文相关领域的权威数据集，对于实体链接而言，公开数据集相对较少。
- 中文百科知识库相较于英文知识库起步较晚且不成熟，限制了实体链接的发展。

---

未来发展：

- 结合更多的上下文信息，如上下文实体的一致性，全局一致性。
- 融入深度学习技术，提高实体链接的准确性和效率。
- 构建更丰富、更全面的中文知识图谱，提供更多的实体链接信息和语义关联。
- 发展领域专用的实体链接方法，提高领域内实体链接的性能。

---

## 心得总结

总的来说，虽然实体链接已经是作为知识图谱领域的一个下游子任务了，但是在实体链接的工作中依然有许多细分的子模块是值得进一步深挖与探究的。

---

## 心得总结

概括说来，在实体链接中，主要有以下几个关键难点。

- 命名实体识别
- 候选实体生成
- 实体消歧
- 无链接指代预测

其中，在实体链接的过程中，**实体消歧**是最为主要且难以绕开的两个环节。在过去几年的研究中，有大量的工作基于深度学习的方法，将人工智能引入到这个环节之中，为实体链接带来了新的活力。不过，其他几个方面的工作因为可能涉及到自然语言文本理解或是难以由深度学习算法根据训练集学习，也许在诸如**命名实体识别**、**候选实体生成**这两块中，大模型的引入能够为我们带来更多的机会。
