# 多语言自回归实体链接

## 摘要

定义：多语言实体链接——将一个特定语言的mention链接到一个多语言的Knowledge Base中。

行为：对于一个给定语言的mention，mGENRE将以自回归的方式从左到右逐词预测目标实体的名称。

优势：
* 有效地交叉编码提及的字符串和实体名称，以获取提及和实体向量之间更多的互动。
* 可以在一个大的数据库中快速搜索，即使是那些没有出现在提及表中的提及，也不需要大规模的向量索引。
* 在完全没有训练数据的语言中，mGENRE将目标语言作为一个潜在的变量，在预测时将目标语言边缘化，让平均准确率提高了50%以上。

## 简介

* 多语言实体链接
  * 长期以来是将一种语言的mention链接到另一种语言（通常是英语）的entity中。
  * 定义一个语言无关的KB能够更好适应多语言，考虑英文没有单其他语言具备的实体描述能力。
    * 大多数解决方案选择提供给一个**统一的实体表示**，或者将多语言描述整理成**一个向量**。

* 本文发现
  * 由于不同语言的源语言和实体名称之间的联系，**保持尽可能多的语言信息**，从而为每个实体提供多种表示方法，是有帮助的。
  * **将所有可用的语言作为目标**，并对可能的选择进行汇总，是处理没有训练数据的源语言的zero-shot设置的有效方法。

* 本文贡献
  * 提出了第一个采用用seq2seq的架构，以自回归的方式逐个token生成100多种语言的实体名称，并以上下文为条件的**多语言实体链接系统mGENRE**：
    * 考虑KB中每个条目的所有语言来扩展实体名称的目录
    * 设计了一个新的目标函数，对所有的语言进行边缘化处理来进行预测。

## 背景

这部分内容与[采用判别修正的高并行自回归实体链接](zh-cn/采用判别修正的高并行自回归实体链接)中的许多内容多有重合，故简要描述。

### 自回归生成

GENRE通过计算分数对每个e∈E进行排名，自回归公式为：$\text{score} \theta(e|x)= \prod pθ(y|x)=Ni=1pθ(yi|y<i,x)$ 其中y是e的标识符中的N个token序列，x是输入（即上下文c和提及m），θ是模型的参数。GENRE基于微调的BART架构，并使用标准的seq2seq目标进行训练，即用教师强迫法最大化输出序列可能性，并用dropout和标签平滑法进行正则化。

### beam search

用限制性beam search进行排名。在测试时，为E中的每个元素计算一个分数，然后对它们进行排序，成本太高。因此，GENRE利用beam search，这是一个既定的近似解码策略，可以有效地浏览搜索空间。与其明确地对E中的所有实体进行评分，不如使用带有k个beams的BS搜索E中的前k个实体。在解码过程中，BS只考虑提前一步（即它以先前的token为条件生成下一个token）。因此，GENRE采用了一个前缀树（trie）来实现有约束的beam search，然后只生成有效的实体标识。

## 模型

定义与语言无关的实体标识：对于每一个实体建立一个标识符集合$\{<l, n_e^l>\}$，l表示语言，n为Wikipedia上以语言l链接到实体e的表述。

标识符策略
1. 为每个实体设定一个典型的文本标识符（即对每个实体，选择一个特定语言的描述作为它的名字）【一对一映射】
2. 定义一个文本表示服和实体的映射，拼接language ID和实体在此语言下的name。【多对一映射】
3. 将特定语言中的标识符的选择作为一个潜在变量。

## 心得体会

在近来大模型的实体链接中，主要分为使用BERT编码到向量空间和采用生成模型两条路。如果说ELQ是向量空间派的一个极致的话，本文则是生成模型派的又一个巅峰了。



## 补充阅读

### 名词解释：zero-shot

zero-shot learning：零次学习。

Zero-shot learning 就是希望我们的模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智能。其中零次（Zero-shot）是指对于要分类的类别对象，一次也不学习。

标准定义：利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效。

与之相近的概念有one-shot learning，few-shot learning等。

Zero-shot learning 指的是我们之前没有这个类别的训练样本。但是我们可以学习到一个映射X->Y。如果这个映射足够好的话，我们就可以处理没有看到的类了。

One-shot learning 指的是我们在训练样本很少，甚至只有一个的情况下，依旧能做预测。这是如何做到呢？可以在一个大数据集上学到general knowledge（具体的说，也可以是X->Y的映射），然后再到小数据上有技巧的update。

而Few-shot learning是小样本学习。如果训练集中，不同类别的样本只有少量，则成为Few-shot learning.
就是给模型待预测类别的少量样本，然后让模型通过查看该类别的其他样本来预测该类别。比如：给小孩子看一张熊猫的照片，那么小孩子到动物园看见熊猫的照片之后，就可以识别出那是熊猫。

### 自回归生成

AR模型

### 边缘化

#### 边缘化的定义

边缘化是一种通过累加一个变量的可能值以判定另一个变量的边缘分布的方法。这听起来有点抽象，让我们看一个例子。

假设我们想知道天气是如何影响英国人的幸福感的，也就是P(幸福感|天气)。

假定我们具有衡量某人的幸福感所需的定义和设备，同时记录了某个英格兰人和某个苏格兰人所处位置的天气。可能苏格兰人通常而言要比英格兰人幸福。所以我们其实在衡量的是P(幸福感, 国|天气)，即，我们同时考察幸福感和国。

边缘化告诉我们，我们可以通过累加国家的所有可能值（英国由3国组成：英格兰、苏格兰、威尔士），得到想要计算的数字，即P(幸福感|天气) = P(幸福感, 国=英格兰|天气) + P(幸福感, 国=苏格兰|天气) + P(幸福感, 国=威尔士|天气)。

这就是了！边缘化让我们累加一些概率以得到想要计算的概率。一旦我们计算出了答案（可能是单一值或一个分布），我们可以得到所需的性质（推断）

如果你正使用概率图模型，那么边缘化是进行精确推断的一种方法（也就是说，你可以写下你关注的分布的精确数值，例如可以基于分布精确计算的均值）。在这种情形下，边缘化有时和变量消除是同义词。

#### 边缘化的例子

假设我们有4枚骰子：4面骰、6面骰、8面骰、10面骰。

**游戏**

* 我把6面骰和8面骰放在红盒内，4面骰和10面骰放在蓝盒内。

* 我从红盒与蓝盒中分别随机选取一枚骰子，然后把它们放在黄盒内。

* 我从黄盒中随机选择一枚骰子，掷骰子并告诉你结果。

进行游戏之后，结果是3。我们想要回答的问题是：骰子更可能来自红盒还是蓝盒？

**求解**

为了求解这一问题，我们需要给定我们掷出了一个3这一条件后，骰子取自红盒的似然，L(盒=红|掷骰=3)，及相应的L(盒=蓝|掷骰=3)。这两个概率中较高的那个是问题的答案。

那么我们如何计算L(盒=红|掷骰=3)和L(盒=蓝|掷骰=3)呢？

首先，似然和概率的关系如下：

L(盒|掷骰) = P(掷骰|盒)

这意味着，L(盒=红|掷骰=3)这一似然等价于给定骰子来自红盒这一条件，投掷出3点的概率，即P(掷骰=3|盒=红)。同理，L(盒=蓝|掷骰=3) = P(掷骰=3|盒=蓝)。

假定我们选择了一个红盒中的骰子。它可能是6面骰或8面骰（各自有50/50的机会）。假设我选择了6面骰。这意味着我必须从黄色盒子中选中6面骰，然后掷出3。这一情形的概率为：

P(掷骰=3, 骰=6面|盒=红) = 1/2 x 1/6

1/2是因为我有50%的机会从红盒中随机选中6面骰，因为盒中还有一枚8面骰。1/6是因为我有一枚6面骰，因此掷出3点的机会是1/6.

注意上面的答案没有包含从黄盒中选中6面骰的概率。这是因为，在这一情形下，从黄盒中选取6面骰的概率是1（你可能以为它是1/2，因为黄盒内有6面骰和从蓝盒中取出来的骰子）。这是因为我们正在计算的是给定骰子取自红盒的前提下一枚6面骰掷出一个3的条件概率。因此，我们选中黄盒中的另一枚骰子的情形是不可能存在的，因为那一枚骰子原本来自蓝盒。所以给定从红盒中取出骰子这一前提，我们只能从黄盒中选择6面骰，因而我们从黄盒中选中6面骰的概率是1。

类似地，我们可以计算结果为3，而我们实际上从红盒中选择了8面骰的概率：

P(掷骰=3, 骰=8面|盒=红) = 1/2 x 1/8

现在我们已经基本上完成了计算骰子来自红盒所需的计算工作。还记得吗？红盒只包含6面骰盒8面骰，因此我们只需找出骰子是6面或8面的概率。这一“或”情形下，我们需要将概率相加。因此，骰子来自于红盒的概率为：

P(掷骰=3|盒=红) = (1/2 x 1/6) + (1/2 x 1/8) = 7/48

同理，骰子来自于蓝盒的概率为：

P(掷骰=3|盒=蓝) = P(掷骰=3, 骰=4面|盒=蓝) + P(掷骰=3, 骰=10面|盒=蓝)= (1/2 x 1/4) + (1/2 x 1/10) = 7/40

P(掷骰=3|盒=蓝)高于P(掷骰=3|盒=红)，基于最大似然，我们可以得出结论骰子更可能来自蓝盒。

### 知识蒸馏 Knowledge Distillation

#### 起因

知识蒸馏被广泛的用于模型压缩和迁移学习当中。开山之作应该是”Distilling the Knowledge in a Neural Network“。这篇文章中，作者的motivation是找到一种方法，把多个模型的知识提炼给单个模型。

知识蒸馏产生的原因是现在的深度学习模型越来越大，例如BERT。在线下处理数据，对时间要求不高的话，还能接受，能跑完就好。但是线上运行，对延迟要求高的话，像BERT这样的大模型，就很难满足要求。因此，就找了找模型压缩的方法。

#### 经过

一般认为模型的参数保留了模型学到的知识，因此最常见的迁移学习的方式就是在一个大的数据集上先做预训练，然后使用预训练得到的参数在一个小的数据集上做微调（两个数据集往往领域不同或者任务不同）。例如先在Imagenet上做预训练，然后在COCO数据集上做检测。在这篇论文中，作者认为可以将模型看成是黑盒子，知识可以看成是输入到输出的映射关系。因此，我们可以先训练好一个teacher网络，然后将teacher的网络的输出结果 $q$ 作为student网络的目标，训练student网络，使得student网络的结果 $p$ 接近 $p$ ，因此，我们可以将损失函数写成 $L = CE(y, p) + \alpha CE(q, p)$ 。这里CE是交叉熵（Cross Entropy），y是真实标签的one-hot编码，q是teacher网络的输出结果，p是student网络的输出结果。

但是，直接使用teacher网络的softmax的输出结果q，可能不大合适。因为，一个网络训练好之后，对于正确的答案会有一个很高的置信度。例如，在MNIST数据中，对于某个2的输入，对于2的预测概率会很高，而对于2类似的数字，例如3和7的预测概率为 $10^{-6}$ 和 $10^{-9}$ 。这样的话，teacher网络学到数据的相似信息（例如数字2和3，7很类似）很难传达给student网络。由于它们的概率值接近0。因此，文章提出了softmax-T，公式如下所示：

$$
q_i = \frac{\exp (z_i / T)}{\sum_j \exp (z_j / T)}
$$

这里 $q_i$ 是student网络学习的对象（soft targets），$z_i$ 是神经网络softmax前的输出logit。如果将T取1，这个公式就是softmax，根据logit输出各个类别的概率。如果T接近于0，则最大的值会越近1，其它值会接近0，近似于one-hot编码。如果T越大，则输出的结果的分布越平缓，相当于平滑的一个作用，起到保留相似信息的作用。如果T等于无穷，就是一个均匀分布。

#### 结果

最终文章根据上述的损失函数对网络进行训练。

1. 在MNIST这个数据集上，先使用大的网络进行训练，测试集错误67个，小网络训练，测试集错误146个。加入soft targets到目标函数中，相当于正则项，测试集的错误降低到了74个。这证明了teacher网络确实把知识转移到了student网络，使得结果变好了。
2. 第二个实验是在speech recognition领域，使用不同的参数训练了10个DNN，对这10个模型的预测结果求平均作为emsemble的结果，相比于单个模型有一定的提升。然后将这10个模型作为teacher网络，训练student网络。得到的Distilled Single model相比于直接的单个网络，也有一定的提升。

#### 结论

知识蒸馏，可以将一个网络的知识转移到另一个网络，两个网络可以是同构或者异构。做法是先训练一个teacher网络，然后使用这个teacher网络的输出和数据的真实标签去训练student网络。知识蒸馏，可以用来将网络从大网络转化成一个小网络，并保留接近于大网络的性能；也可以将多个网络的学到的知识转移到一个网络中，使得单个网络的性能接近emsemble的结果。