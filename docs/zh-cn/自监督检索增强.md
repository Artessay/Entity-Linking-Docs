# 自监督检索增强

## 摘要

大语言模型由于仅依赖其自身参数中所拥有的知识，因此其生成的内容中常常会包含一些不准确的事实。
为此，可以通过检索相关知识，来增强大语言模型。

然而，不加选择地堆砌相关内容而不管这些内容是否相关，将降低大语言模型的通用性，并可能产生没有帮助的回答。

本文引入了一种新的自监督检索增强框架来增强大语言模型生成的质量和准确性。

框架通过检索和自我反思来保证数据质量。
我们通过训练一个大模型自适应地按需检索段落，生成内容，并用一些特殊的自我反思字符（reflection tokens）对自己生成的内容进行反思。

这些反思字符能够让大模型在推理阶段变得可控，并使其能够根据不同的任务需求来调整自己的行为。

实验表明，在开放问答、推理和事实验证领域上，Self-RAG能够比现有的大模型做得更好。